{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79f76757-ebe4-45c4-ae61-42be3d6f8d1c",
   "metadata": {},
   "source": [
    "# Inteligencia artificial: Generación de Prompts\n",
    "* Curso 67075\n",
    "* IA: Entretejiendo imaginación y algoritmos \n",
    "* Raúl Andrés De Roovers\n",
    "* Entrega Final\n",
    "\n",
    "## Introducción\n",
    "* Nombre del Proyecto:\n",
    "   * Crónicas del Estudiante de Ingeniería: Generación Automática de Contenido\n",
    "\n",
    "### El Problema\n",
    "Durante el Curso 66130, Fundamentos de Inteligencia Artificial, se desarrolló un blog con relatos de estudiantes de ingeniería:\n",
    "   * https://cronicasestudianteingenieria.framer.ai/\n",
    "\n",
    "El siguiente paso para darle vida a este blog es alimentarlo frecuentemente (incorporando al menos un relato por semana) con una gran cantidad de relatos de diferentes estudiantes que puedan enriquecer la experiencia del usuario que visita el sitio, al poder leer experiencias mucho más variadas y numerosas. El problema en cuestión incluye la generación de los siguientes ítems:\n",
    "\n",
    "* Perfil del estudiante: Nombre, Apellido, Nacionalidad y Edad\n",
    "* Bio del estudiante\n",
    "* Foto de perfil del estudiante\n",
    "* Relato (acompañado de un título)\n",
    "\n",
    "Inicialmente, la generación de la información recién mencionada consiste en un proceso manual, a través del cual la persona encargada de mantener el sitio debe iniciar sesión en una herramienta de generación de texto y utilizar un prompt para generar los datos necesarios, incluyendo la solicitud de un prompt que sirva para generar una imagen de perfil del estudiante. Luego, esta misma persona debe iniciar sesión en una herramienta de generación de imágenes a partir de texto, para mediante la introducción del prompt recién generado, obtener la imagen de perfil para este nuevo estudiante.\n",
    "\n",
    "Además, como parte del mismo proceso manual, el encargado de mantenimiento del sitio debe subir esta información a un repositorio y notificar de alguna manera al mismo sitio para que actualice el relato de la semana, utilizando la información recién generada.\n",
    "\n",
    "Este proceso manual puede ser reemplazado por un proceso automático que permita al encargado de mantenimiento dirigir su atención y utilizar su tiempo en tareas de mantenimiento y mejora del sitio, incluso de publicidad; incorporando valor desde otras áreas y eliminando la repetición de una tarea sistemática.\n",
    "\n",
    "### La Solución\n",
    "En este contexto, se plantea como solución la utilización de modelos de IA que conviertan texto a texto y texto a imágenes, y nos permitan solucionar el problema en cuestión de manera inmediata y contando con una “base de datos” (de estudiantes y relatos) virtualmente infinita.\n",
    "\n",
    "El objetivo principal será la generación mediante la utilización de herramientas de IA, de un perfil de estudiante, que estará compuesto por:\n",
    "\n",
    "* Nombre y apellido\n",
    "* Edad\n",
    "* País de origen\n",
    "* Bio\n",
    "* Imagen de perfil\n",
    "* Un relato único para dicho estudiante, que cuente con un título propio y significativo.\n",
    "\n",
    "Se dividirán las tareas según los pasos que se detallan a continuación. Queda fuera del alcance de la presente solución, el proceso de carga de los datos obtenidos al sitio web, como también la configuración de un timer para la ejecución del programa/script en cuestión, la actualización del blog y una posible notificación a los potenciales suscriptores.\n",
    "\n",
    "#### Paso 1: Generación de datos básicos del estudiante\n",
    "\n",
    "Los datos básicos del estudiante son: Nombre, Apellido, Edad, País de origen, rama de Ingeniería que estudia, longitud del pelo, color del pelo, color de ojos y expresión.\n",
    "\n",
    "Se solicitan características físicas del estudiante para generar una imagen de perfil mas representativa.\n",
    "\n",
    "#### Paso 2: Generación de bio del estudiante\n",
    "\n",
    "Se solicitará a la IA que genere una bio para el estudiante, utilizando los datos obtenidos en el paso anterior y aplicando la técnica few-shot prompting al proveer a la IA de algunos ejemplos en los cuales basar su respuesta.\n",
    "\n",
    "#### Paso 3: Generación del relato y su título\n",
    "\n",
    "Se solicitará a la IA que genere una bio para el estudiante, utilizando los datos obtenidos en el Paso 1 y aplicando la técnica few-shot prompting al proveer a la IA de algunos ejemplos en los cuales basar su respuesta.\n",
    "\n",
    "#### Paso 4: Generación de la imagen de perfil\n",
    "\n",
    "Se solicitará a la IA que genere una imagen de perfil del estudiante, utilizando una plantilla pre-definida y completándola con los datos obtenidos en el Paso 1.\n",
    "\n",
    "#### Paso 5: Generación del audio del relato - experimental\n",
    "\n",
    "Se solicitará a la IA que genere un audio a partir del relato obtenido en el Paso 3.\n",
    "\n",
    "#### Prompts a utilizar\n",
    "\n",
    "##### Contexto\n",
    "\n",
    "Se le indicará a la IA que se trata de un asistente de generación de contenido para un blog de relatos de estudiantes de ingeniería que semanalmente incorpora relatos acompañados con los datos y una foto de perfil del estudiante.\n",
    "\n",
    "```\n",
    "Eres un asistente de generación de contenido para un blog de relatos de estudiantes de ingeniería, que incorpora semanalmente el relato de un estudiante incluyendo además los datos de perfil y una foto del mismo\n",
    "```\n",
    "\n",
    "##### Datos básicos del estudiante\n",
    "\n",
    "```\n",
    "En base a los siguientes ejemplos, necesito que inventes un nuevo estudiante y me respondas solamente con los datos separados por pipes como estan provistos:\n",
    "    |Nombre|Apellido|Edad|Pais|Ingenieria|Longitud|Color|Ojos|Expresion|\n",
    "    |Sophia|Rodríguez|23|México|Ambiental|Largo|Negro|Marrones|Serena|\n",
    "    |Diego|Gómez|25|Colombia|Civil|Corto|Negro|Grises|Concentrada|\n",
    "    |Juan|Pérez|22|Argentina|Mecánica|Rapado|Rubio|Celestes|Tímida|\n",
    "```\n",
    "\n",
    "##### Bio del estudiante\n",
    "\n",
    "```\n",
    "En base a los siguientes ejemplos, necesito que inventes una bio para {nombre} {apellido}, estudiante de ingeniería {rama} de {edad} años, de {pais}. No mas de 50 palabras.\n",
    "    * Sophia Rodríguez es una estudiante de ingeniería ambiental apasionada por la conservación del medio ambiente y la sostenibilidad. Originaria de México, se destaca por su compromiso con proyectos que buscan mitigar el impacto ambiental y promover prácticas ecoamigables en la industria.\n",
    "    * Diego Gómez es un estudiante de ingeniería civil con una pasión por diseñar infraestructuras innovadoras que mejoren la calidad de vida de las personas. Originario de Colombia, se destaca por su dedicación a proyectos de desarrollo urbano y su compromiso con la construcción sostenible.\n",
    "    * Juan Pérez es un estudiante de ingeniería mecánica con una pasión desenfrenada por la robótica. Originario de Argentina, se destaca por su habilidad para diseñar y construir robots innovadores. Su determinación y creatividad lo convierten en un talento prometedor en el campo de la ingeniería.\n",
    "```\n",
    "\n",
    "##### Relato y título\n",
    "```\n",
    "Necesito que inventes un relato en primera persona, de 250 palabras, junto con su titulo, para una experiencia que haya vivido {nombre} {apellido}, de {edad} años, durante su carrera universitaria de ingenieria {rama}. Te proveo ejemplos:\n",
    "    * Armada con cafeína y determinación, me uní a un grupo de estudiantes de ingeniería informática para embarcarnos en un hackatón de 24 horas con el objetivo de desarrollar una aplicación de software innovadora. A pesar de la privación de sueño y la creciente presión, nuestra creatividad y trabajo en equipo florecieron mientras enfrentábamos desafíos de codificación complejos y generábamos soluciones innovadoras.  Durante toda la jornada, nos sumergimos en el mundo del desarrollo de software, aprovechando cada momento para colaborar y perfeccionar nuestra creación. A medida que avanzaba la noche, la adrenalina y la emoción se apoderaban de nosotros, impulsándonos a superar obstáculos y encontrar soluciones ingeniosas.  Finalmente, después de intensas horas de trabajo, llegó el momento de presentar nuestro prototipo completamente funcional ante un panel de jueces. La tensión en el aire era palpable mientras esperábamos ansiosamente el veredicto. Cuando escuchamos nuestro nombre llamado como ganadores, una oleada de emoción y orgullo nos invadió.  El esfuerzo valió la pena cuando recibimos los máximos honores y reconocimiento por nuestro ingenio y habilidades técnicas. Aquel hackatón no solo fue una prueba de nuestras habilidades, sino también una experiencia inolvidable de trabajo en equipo, perseverancia y superación de desafíos.\n",
    "    * Durante una sesión práctica en el laboratorio, me encontré luchando por resolver un problema de ingeniería que parecía ser simple. A pesar de siempre destacar académicamente, me sentí frustrado al ver cómo mis compañeros de clase completaban la tarea con facilidad. Decidí tragarme mi orgullo y pedir ayuda a uno de mis compañeros. Con humildad, me acerqué a él y le expliqué mi situación. Para mi sorpresa, él no solo me ofreció su ayuda, sino que también me guió pacientemente a través del problema. Juntos, trabajamos en equipo para encontrar la solución. A medida que avanzábamos, ganaba un nuevo aprecio por el valor de la humildad y el poder del trabajo en equipo en la búsqueda del conocimiento. Al final, no solo encontramos la solución al problema, sino que también fortalecimos nuestra amistad y aprendí una valiosa lección sobre la importancia de pedir ayuda cuando la necesito y reconocer que siempre hay algo nuevo que aprender de los demás.\n",
    "    * Una noche durante la semana de exámenes finales, decidimos, un grupo de estudiantes de ingeniería, tomar un respiro de tanto estudio y aventurarnos a explorar el campus. Mientras caminábamos, nos encontramos con el jardín en la azotea de la universidad, un lugar que rara vez visitábamos. La puerta que conducía a la sala de máquinas estaba desbloqueada, y con una mezcla de curiosidad y travesura, decidimos aventurarnos dentro. Una vez dentro, nos sumergimos en la oscuridad de la sala, apenas iluminada por la luz de nuestros teléfonos. Nos movíamos con cautela, explorando cada rincón con la emoción de estar en un lugar prohibido. Sin embargo, nuestro entusiasmo se convirtió rápidamente en preocupación cuando uno de nosotros tropezó con un interruptor y, en un instante, la sala quedó sumida en la oscuridad total. El pánico se apoderó de nosotros mientras intentábamos encontrar una solución. La idea de haber dejado a toda la universidad a oscuras nos llenó de nerviosismo y culpabilidad. Finalmente, después de unos momentos de caos, logramos restaurar la energía y devolver la luz a la universidad. Fue una experiencia que nunca olvidaremos. Aprendimos una valiosa lección sobre la importancia de la precaución y la humildad. A veces, la curiosidad puede llevarnos a situaciones inesperadas, pero es importante recordar que siempre debemos actuar con responsabilidad y consideración hacia los demás.\n",
    "```\n",
    "\n",
    "##### Imagen de perfil\n",
    "\n",
    "```\n",
    "Foto de perfil de {nombre} {apellido}, estudiante de ingeniería {rama} de {pais}, de {edad} años. Tiene una expresión {expresion}, la longitud del pelo es {longitud_pelo}, de color {color_pelo}. Sus ojos son {color_ojos}\n",
    "```\n",
    "\n",
    "\n",
    "##### Audio del relato\n",
    "\n",
    "* Se utilizará como input, el relato obtenido en el Paso 3.\n",
    "\n",
    "### Análisis de Viabilidad\n",
    "\n",
    "Para analizar la viabilidad de la solución propuesta, tendremos en cuenta principalmente dos variables: tiempo y recursos.\n",
    "\n",
    "### Tiempo\n",
    "\n",
    "#### Implementación\n",
    "\n",
    "**En base a los conocimientos previos** del lenguaje Python, de la utilización de IDEs como Visual Studio Code y a la interacción con APIs; **el desarrollo del código fuente** que interactúe con la API de OpenAI **constituye una tarea de dificultad baja, siendo su duración de dos días aproximadamente**.\n",
    "\n",
    "La estimación está basada en la cantidad y dificultad de los pasos que hemos visto en clase, donde una vez obtenida una API Key, necesitamos definir un contexto y luego los prompts a utilizar.\n",
    "\n",
    "Al mismo tiempo, dada la propuesta de solución, la lógica a implementar constaría de tres llamadas a la API de OpenAI:\n",
    "1. Generación de datos básicos del estudiante: nombre, apellido, edad, pais, rama de ingeniería, longitud del pelo, color del pelo, color de ojos y expresión.\n",
    "2. Generación de bio del estudiante.\n",
    "3. Generación del relato y su título.\n",
    "4. Generación de la imagen de perfil.\n",
    "5. Generación del audio del relato.\n",
    "\n",
    "Una vez obtenidos los datos básicos del estudiante (Paso 1), se procederá a solicitar la generación de la bio (Paso 2) y luego la generación del relato y su título (Paso 3). A continuación, se creará una carpeta en el sistema utilizando nombre y apellido con el siguiente formato: `{nombre}.{apellido}` y se agregará a la carpeta recién creada, un archivo con el nombre `data.json` que contendrá los datos obtenidos para el estudiante con el siguiente formato (en JSON):\n",
    "\n",
    "```\n",
    "{\n",
    "    \"name\": \"{nombre}\",\n",
    "    \"surname\": \"{apellido}\",\n",
    "    \"country\": \"{pais}\",\n",
    "    \"age\": \"{edad}\",\n",
    "    \"branch\": \"{rama}\",\n",
    "    \"hair_length\": \"{longitud_pelo}\",\n",
    "    \"hair_color\": \"{color_pelo}\",\n",
    "    \"eye_color\": \"{color_ojos}\",\n",
    "    \"expression\": \"{expresion}\",\n",
    "    \"bio\": \"{bio}\",\n",
    "    \"tale_title\": \"{titulo}\",\n",
    "    \"tale\": \"{relato}\",\n",
    "    \"prompt\": \"{prompt}\"\n",
    "}\n",
    "```\n",
    "\n",
    "Luego, se procederá a obtener la imagen de perfil (Paso 4), la cual se almacenará también dentro de la carpeta del estudiante, en formato `png` y utilizando como nombre una marca de tiempo con el siguiente formato:\n",
    "* `perfil-{año}{mes}{día}{hora}{minuto}{segundo}{microsegundo}`\n",
    "    * Ejemplo: `perfil-20240422232642383803.png`\n",
    "\n",
    "Finalmente, se procederá a obtener el audio del relato. La herramienta a utilizar dependerá de la configuración elegida, detallada a continuación:\n",
    "\n",
    "* Opción 1: gTTS (Google Text-to-Speech) - Free\n",
    "   * Asignando el valor `True` a la variable `use_gtts`\n",
    "* Opción 2: OpenAI (Text-to-Speech) - Paid\n",
    "   * Asignando el valor `False` a la variable `use_gtts`\n",
    " \n",
    "El audio obtenido se almacenará en formato `mp3` dentro de la carpeta del estudiante, utilizando como nombre una marca de tiempo con el siguiente formato:\n",
    "* `relato-{año}{mes}{día}{hora}{minuto}{segundo}{microsegundo}`\n",
    "    * Ejemplo: `relato-20240422232642383803.mp3`\n",
    " \n",
    "#### Definición de Prompts\n",
    "Las **pruebas preliminares consumieron** un aproximado de **tres días** para la obtención de los prompts necesarios para obtener los resultados deseados.\n",
    "\n",
    "Se estima que la **optimización de** estos **prompts** consumirá un **máximo de un día**.\n",
    "\n",
    "### Recursos\n",
    "\n",
    "#### Herramientas\n",
    "\n",
    "##### ChatGPT (web)\n",
    "\n",
    "Se utilizará ChatGPT web para las pruebas preliminares que nos permitan definir los prompts a utilizar, ya que su uso es libre y gratuito y podremos realizar tantas pruebas como sea necesario para optimizar nuestros prompts.\n",
    "* https://chat.openai.com/\n",
    "\n",
    "##### Visual Studio Code\n",
    "\n",
    "Se utilizará este IDE para la implementación del código en Python que concentre los prompts y realice las sucesivas llamadas a la API de OpenAI para obtener y recopilar los resultados deseados. También es importante en este punto, no sólo la gratuidad de Visual Studio Code sino la facilidad que presenta en la incorporación de plugins y la familiaridad del desarrollador para con la herramienta.\n",
    "* https://code.visualstudio.com/\n",
    "\n",
    "##### Conda\n",
    "\n",
    "Será utilizado para poder administrar los paquetes y entornos de Python.\n",
    "* https://docs.conda.io/en/latest/\n",
    "\n",
    "##### Texto a Texto\n",
    "\n",
    "Para la generación de texto se utilizará la API de GPT-3:\n",
    "* GPT-3.5 Turbo: gpt-3.5-turbo-0125\n",
    "* Versión: openai 0.28.0\n",
    "\n",
    "Esta elección se basa en que se trata de la versión estándar, que presenta resultados acorde a las necesidades de nuestro proyecto y también un costo menor al de la versión *gpt-3.5-turbo-instruct* y mucho menor a los modelos *GPT-4* y *GPT-4 Turbo*.\n",
    "* https://platform.openai.com/docs/guides/text-generation/chat-completions-api\n",
    "\n",
    "##### Texto a Imagen\n",
    "\n",
    "Para la generación de imágenes se utilizará la API de DALL-E:\n",
    "* DALL·E 2, Standard, 1024×1024\n",
    "* Versión: openai 0.28.0\n",
    "\n",
    "Se decidió utilizar esta versión en particular dado DALL·E 3 no permite su uso gratuito.\n",
    "* https://platform.openai.com/docs/guides/images?context=node\n",
    "\n",
    "##### Texto a Audio\n",
    "\n",
    "Para la generación de texto a audio se cuenta con 2 opciones:\n",
    "\n",
    "* Opción 1: gTTS (Google Text-to-Speech)\n",
    "   * Esta opción es gratuita.\n",
    "   * https://gtts.readthedocs.io/en/latest/\n",
    "* Opción 2: OpenAI (Text-to-Speech) - Paid\n",
    "   * Esta opción es paga y no se encuentra disponible en la versión 0.28.0 de la API de OpenAI, por lo cual se debe hacer un request directo al endpoint público, utilizando el token como encabezado de autorización.\n",
    "   * https://platform.openai.com/docs/guides/text-to-speech\n",
    "\n",
    "##### Costos\n",
    "\n",
    "Para el cálculo de los costos se utilizará la documentación de OpenAI.\n",
    "* https://openai.com/pricing\n",
    "\n",
    "##### Estimación de palabras\n",
    "\n",
    "Para el cálculo de la cantidad de palabras de cada fragmento se utilizará Quillbot - Word Counter.\n",
    "* *https://quillbot.com/word-counter\n",
    "\n",
    "##### Cálculo de tokens\n",
    "\n",
    "Para el cálculo de la cantidad de tokens insumidos se utilizará Tokenizer (de OpenAI).\n",
    "* https://platform.openai.com/tokenizer\n",
    "\n",
    "#### Costos\n",
    "\n",
    "* Paso 1.\n",
    "    * Contexto: 50 tokens\n",
    "    * Prompt Tokens: 160\n",
    "    * Max Tokens: 100\n",
    "* Paso 2.\n",
    "    * Contexto: 50 tokens\n",
    "    * Prompt Tokens: (max) 300\n",
    "    * Max Tokens: 80\n",
    "* Paso 3.\n",
    "    * Contexto: 50 tokens\n",
    "    * Prompt Tokens: (max) 1100\n",
    "    * Max Tokens: 450\n",
    "* Paso 4.\n",
    "    * Fijo: 1 imagen\n",
    "* Paso 5.\n",
    "    * gTTS: 0\n",
    "    * OpenAI TTS: (max) 2000 caracteres\n",
    " \n",
    "Consultando entonces la documentación de OpenAI, vemos los siguientes valores:\n",
    "\n",
    "![image info](text.to.text.png)\n",
    "\n",
    "![image info](text.to.image.png)\n",
    "\n",
    "![image info](text.to.speech.png)\n",
    "\n",
    "Podemos entonces definir nuestros costos en base a la siguientes tablas, según la opción elegida para la generación de audio:\n",
    "\n",
    "##### gTTS\n",
    "| Paso | Descripción | Contexto | Prompt | Output | Costo Token Input | Costo Token Output | Costo Input (Contexto + Prompt) | Costo Output | Costo del Paso |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | Generacion de datos basicos | 50 | 160 | 100 | 0,0000005 | 0,0000015 | 0,000105 | 0,00015 | 0,000255 |\n",
    "| 2 | Generacion de bio | 50 | 300 | 80 | 0,0000005 | 0,0000015 | 0,000175 | 0,00012 | 0,000295 |\n",
    "| 3 | Generacion de relato y titulo | 50 | 1100 | 450 | 0,0000005 | 0,0000015 | 0,000575 | 0,000675 | 0,00125 |\n",
    "| 4 | Generacion de imagen de perfil | 0 | 0 | 1 | 0 | 0,02 | 0 | 0,02 | 0,02 |\n",
    "| 5 | Generacion de audio del relato | 0 | 0 | 2000 | 0 | 0 | 0 | 0 | 0 |\n",
    "| TOTAL |  |  |  |  |  |  |  |  | 0,0218 |\n",
    "\n",
    "##### OpenAI TTS\n",
    "\n",
    "\n",
    "| Paso | Descripción | Contexto | Prompt | Output | Costo Token Input | Costo Token Output | Costo Input (Contexto + Prompt) | Costo Output | Costo del Paso |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | Generacion de datos basicos | 50 | 160 | 100 | 0,0000005 | 0,0000015 | 0,000105 | 0,00015 | 0,000255 |\n",
    "| 2 | Generacion de bio | 50 | 300 | 80 | 0,0000005 | 0,0000015 | 0,000175 | 0,00012 | 0,000295 |\n",
    "| 3 | Generacion de relato y titulo | 50 | 1100 | 450 | 0,0000005 | 0,0000015 | 0,000575 | 0,000675 | 0,00125 |\n",
    "| 4 | Generacion de imagen de perfil | 0 | 0 | 1 | 0 | 0,02 | 0 | 0,02 | 0,02 |\n",
    "| 5 | Generacion de audio del relato | 0 | 0 | 2000 | 0 | 0,000015 | 0 | 0,03 | 0,03 |\n",
    "| TOTAL |  |  |  |  |  |  |  |  | 0,0518 |\n",
    "\n",
    "Concluimos entonces que con cada generación de un estudiante incurrimos en un gasto de:\n",
    "* gTTS: \\$0,0218 (dólares)\n",
    "* OpenAI TTS: \\$0,0518 (dólares)\n",
    "\n",
    "Considerando que la actualización del blog se realiza en forma semanal, y considerando un promedio de 53 semanas al año, obtenemos el siguiente costo anual:\n",
    "\n",
    "* \\$1,1554 (dólares), optando por generar el audio del relato con la librería gratuita gTTS.\n",
    "* \\$2,7454 (dólares), optando por generar el audio del relato con la librería paga Open AI TTS.\n",
    "\n",
    "#### Conclusión\n",
    "\n",
    "En base al análisis anterior, podemos concluir que un tiempo de desarrollo cercano pero inferior a una semana con un costo de mantenimiento anual menor a los tres dólares, resulta absolutamente viable.\n",
    "\n",
    "Asimismo, se aconseja el uso de la librearía paga Open AI TTS para la generación del audio del relato, ya que los resultados son abismalmente mejores a los obtenidos con la librería gratuita gTTS.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "* Automatizar mediante el uso de herramientas de IA, la generación de contenido para un sitio web que publica semanalmente relatos de estudiantes de ingeniería de todo el mundo.\n",
    "\n",
    "## Metodología:\n",
    "\n",
    "Implementaremos la solución propuesta en la sección *La Solución* mediante un programa desarrollado en Python. Se utilizarán los prompts decriptos en la sescción *La Solución* > *Prompts a utilizar*, donde hemos mejorado la calidad de las respuestas respecto de la Pre-Entrega 1 al utilizar la técnica de **Few-Shot Prompting**. Además, en la sección *Análisis de Viabilidad* > *Tiempo* > *Implementación*, hemos descripto los pasos con los que deberá contar nuestro programa para garantizar el correcto almacenamiento de los datos obtenidos.\n",
    "\n",
    "## Herramientas y tecnologías\n",
    "\n",
    "* Descriptas en la sección *Análisis de Viabilidad* > *Recursos*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ef64a-9a31-4e0d-98b7-ce048c6a9cbe",
   "metadata": {},
   "source": [
    "## Implementación\n",
    "\n",
    "NOTA: La implementación está basada en la versión 0.28.0 de la API de OpenAI, que utiliza ChatCompletion. Esta funcionalidad fue removida a partir de la versión 1.0.0, tal como indica el error que se produce al querer ejecutar el codigo aquí adjunto en la propia Jupyter Notebook:\n",
    "\n",
    "```\n",
    "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
    "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
    "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
    "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
    "```\n",
    "\n",
    "Decidí mantener la versión para atenerme a los ejemplos vistos en clase. El código funciona y fue probado repetidas veces bajo la versión 0.28.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efcfa1-1c48-4407-881c-3b38dee935fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from gtts import gTTS\n",
    "import json\n",
    "import logging\n",
    "import openai\n",
    "import os\n",
    "import requests\n",
    "\n",
    "normalMap = {'À': 'A', 'Á': 'A', 'Â': 'A', 'Ã': 'A', 'Ä': 'A',\n",
    "             'à': 'a', 'á': 'a', 'â': 'a', 'ã': 'a', 'ä': 'a', 'ª': 'A',\n",
    "             'È': 'E', 'É': 'E', 'Ê': 'E', 'Ë': 'E',\n",
    "             'è': 'e', 'é': 'e', 'ê': 'e', 'ë': 'e',\n",
    "             'Í': 'I', 'Ì': 'I', 'Î': 'I', 'Ï': 'I',\n",
    "             'í': 'i', 'ì': 'i', 'î': 'i', 'ï': 'i',\n",
    "             'Ò': 'O', 'Ó': 'O', 'Ô': 'O', 'Õ': 'O', 'Ö': 'O',\n",
    "             'ò': 'o', 'ó': 'o', 'ô': 'o', 'õ': 'o', 'ö': 'o', 'º': 'O',\n",
    "             'Ù': 'U', 'Ú': 'U', 'Û': 'U', 'Ü': 'U',\n",
    "             'ù': 'u', 'ú': 'u', 'û': 'u', 'ü': 'u',\n",
    "             'Ñ': 'N', 'ñ': 'n',\n",
    "             'Ç': 'C', 'ç': 'c',\n",
    "             '§': 'S',  '³': '3', '²': '2', '¹': '1'}\n",
    "normalize = str.maketrans(normalMap)\n",
    "\n",
    "class Student:\n",
    "    __name: str\n",
    "    __surname: str\n",
    "    __age: int\n",
    "    __country: str\n",
    "    __branch: str\n",
    "    __hair_length: str\n",
    "    __hair_color: str\n",
    "    __eye_color: str\n",
    "    __expression: str\n",
    "    __bio: str\n",
    "    __tale_title: str\n",
    "    __tale: str\n",
    "    __prompt: str\n",
    "\n",
    "    def __init__(self, name: str, surname: str, age: int, country: str, branch: str, hair_length: str, hair_color: str, eye_color: str, expression: str):\n",
    "        self.__name = name\n",
    "        self.__surname = surname\n",
    "        self.__age = age\n",
    "        self.__country = country\n",
    "        self.__branch = branch\n",
    "        self.__hair_length = hair_length\n",
    "        self.__hair_color = hair_color\n",
    "        self.__eye_color = eye_color\n",
    "        self.__expression = expression\n",
    "        self.__bio = \"\"\n",
    "        self.__tale_title = \"\"\n",
    "        self.__tale = \"\"\n",
    "        self.__prompt = \"Foto de perfil de {} {}, estudiante de ingeniería {} de {}, de {} años. Tiene una expresión {}, la longitud del pelo es {}, de color {}. Sus ojos son {}\".format(name, surname, branch, country, age, expression.lower(), hair_length.lower(), hair_color.lower(), eye_color.lower())\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Name: {} {}, Age: {}, Country: {}, Branch: {}, Hair Length: {}, Hair Color: {}, Eye Color: {}, Expression: {}\\nBio: {}\\nTale: {}\\n{}\\nPrompt: {}\".format(self.__name, self.__surname, self.__age, self.__country, self.__branch, self.__hair_length, self.__hair_color, self.__eye_color, self.__expression, self.__bio, self.__tale_title, self.__tale, self.__prompt)\n",
    "    \n",
    "    def get_name(self):\n",
    "        return self.__name\n",
    "\n",
    "    def get_surname(self):\n",
    "        return self.__surname\n",
    "    \n",
    "    def get_age(self):\n",
    "        return self.__age\n",
    "    \n",
    "    def get_country(self):\n",
    "        return self.__country\n",
    "    \n",
    "    def get_branch(self):\n",
    "        return self.__branch\n",
    "\n",
    "    def get_prompt(self):\n",
    "        return self.__prompt\n",
    "    \n",
    "    def set_bio(self, bio):\n",
    "        self.__bio = bio\n",
    "    \n",
    "    def set_tale_title(self, title):\n",
    "        self.__tale_title = title\n",
    "\n",
    "    def set_tale(self, tale):\n",
    "        self.__tale = tale\n",
    "    \n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            'name': self.__name,\n",
    "            'surname': self.__surname,\n",
    "            'age': self.__age,\n",
    "            'country': self.__country,\n",
    "            'branch': self.__branch,\n",
    "            'hair_length': self.__hair_length,\n",
    "            'hair_color': self.__hair_color,\n",
    "            'eye_color': self.__eye_color,\n",
    "            'expression': self.__expression,\n",
    "            'bio': self.__bio,\n",
    "            'tale_title': self.__tale_title,\n",
    "            'tale': self.__tale,\n",
    "            'prompt': self.__prompt,\n",
    "        }\n",
    "\n",
    "def get_timestamp():\n",
    "    now = datetime.datetime.now()\n",
    "    year = '{:02d}'.format(now.year)\n",
    "    month = '{:02d}'.format(now.month)\n",
    "    day = '{:02d}'.format(now.day)\n",
    "    hour = '{:02d}'.format(now.hour)\n",
    "    minute = '{:02d}'.format(now.minute)\n",
    "    second = '{:02d}'.format(now.second)\n",
    "    microsecond = '{:02d}'.format(now.microsecond)\n",
    "    timestamp = '{}{}{}{}{}{}{}'.format(year, month, day, hour, minute, second, microsecond)\n",
    "    return timestamp\n",
    "\n",
    "def download_image(url: str, folder: str):\n",
    "    response = requests.get(url)\n",
    "    timestamp = get_timestamp()\n",
    "    file_name = \"{}/perfil-{}.png\".format(folder, timestamp)\n",
    "    with open(file_name, 'wb') as handler:\n",
    "        handler.write(response.content)\n",
    "    return file_name\n",
    "\n",
    "def create_student_from_parts(parts: list):\n",
    "    return Student(parts[0], parts[1], parts[2], parts[3], parts[4], parts[5], parts[6], parts[7], parts[8])\n",
    "\n",
    "def create_student(context: str):\n",
    "    # User Role\n",
    "    prompt = \"\"\"\n",
    "    En base a los siguientes ejemplos, necesito que inventes un nuevo estudiante y me respondas solamente con los datos separados por pipes como estan provistos:\n",
    "    |Nombre|Apellido|Edad|Pais|Ingenieria|Longitud|Color|Ojos|Expresion|\n",
    "    |Sophia|Rodríguez|23|México|Ambiental|Largo|Negro|Marrones|Serena|\n",
    "    |Diego|Gómez|25|Colombia|Civil|Corto|Negro|Grises|Concentrada|\n",
    "    |Juan|Pérez|22|Argentina|Mecánica|Rapado|Rubio|Celestes|Tímida|\n",
    "    \"\"\"\n",
    "\n",
    "    # Conversation/Request\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    logging.info(\"Ejecutando solicitud para ChatCompletion (Nombre, Apellido, Edad, Pais, Ingeniería, Longitud, Color, Ojos y Expresión)...\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # gpt-3.5-turbo-0125 -> default\n",
    "        messages=conversation,\n",
    "        max_tokens=100,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    logging.info(\"Solicitud completada, el estudiante ha sido creado con éxito!\")\n",
    "    \n",
    "    message = response['choices'][0]['message']\n",
    "    raw_student = message['content']\n",
    "    \n",
    "    raw_student = raw_student.split(\"\\n\")[1]\n",
    "    parts = raw_student.replace(\"\\\"\", \"\").split(\"|\")\n",
    "    parts = list(filter(None, parts))\n",
    "    student = create_student_from_parts(parts)\n",
    "\n",
    "    return student\n",
    "\n",
    "def create_bio(context: str, student: Student):\n",
    "    # User Role\n",
    "    prompt = \"\"\"\n",
    "    En base a los siguientes ejemplos, necesito que inventes una bio para {} {}, estudiante de ingeniería {} de {} años, de {}. No mas de 50 palabras.\n",
    "    * Sophia Rodríguez es una estudiante de ingeniería ambiental apasionada por la conservación del medio ambiente y la sostenibilidad. Originaria de México, se destaca por su compromiso con proyectos que buscan mitigar el impacto ambiental y promover prácticas ecoamigables en la industria.\n",
    "    * Diego Gómez es un estudiante de ingeniería civil con una pasión por diseñar infraestructuras innovadoras que mejoren la calidad de vida de las personas. Originario de Colombia, se destaca por su dedicación a proyectos de desarrollo urbano y su compromiso con la construcción sostenible.\n",
    "    * Juan Pérez es un estudiante de ingeniería mecánica con una pasión desenfrenada por la robótica. Originario de Argentina, se destaca por su habilidad para diseñar y construir robots innovadores. Su determinación y creatividad lo convierten en un talento prometedor en el campo de la ingeniería.\n",
    "    \"\"\".format(student.get_name(), student.get_surname(), student.get_branch(), student.get_age(), student.get_country())\n",
    "\n",
    "    # Conversation/Request\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    logging.info(\"Ejecutando solicitud para ChatCompletion (Bio)...\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # gpt-3.5-turbo-0125 -> default\n",
    "        messages=conversation,\n",
    "        max_tokens=80,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    logging.info(\"Solicitud completada, la bio ha sido creada con éxito!\")\n",
    "    \n",
    "    message = response['choices'][0]['message']\n",
    "    bio = message['content']\n",
    "\n",
    "    return bio\n",
    "\n",
    "def create_tale(context: str, student: Student):\n",
    "    # User Role\n",
    "    prompt = \"\"\"\n",
    "    Necesito que inventes un relato en primera persona, de 250 palabras, junto con su titulo, para una experiencia que haya vivido {} {}, de {} años, durante su carrera universitaria de ingenieria {}. Te proveo ejemplos:\n",
    "    * Armada con cafeína y determinación, me uní a un grupo de estudiantes de ingeniería informática para embarcarnos en un hackatón de 24 horas con el objetivo de desarrollar una aplicación de software innovadora. A pesar de la privación de sueño y la creciente presión, nuestra creatividad y trabajo en equipo florecieron mientras enfrentábamos desafíos de codificación complejos y generábamos soluciones innovadoras.  Durante toda la jornada, nos sumergimos en el mundo del desarrollo de software, aprovechando cada momento para colaborar y perfeccionar nuestra creación. A medida que avanzaba la noche, la adrenalina y la emoción se apoderaban de nosotros, impulsándonos a superar obstáculos y encontrar soluciones ingeniosas.  Finalmente, después de intensas horas de trabajo, llegó el momento de presentar nuestro prototipo completamente funcional ante un panel de jueces. La tensión en el aire era palpable mientras esperábamos ansiosamente el veredicto. Cuando escuchamos nuestro nombre llamado como ganadores, una oleada de emoción y orgullo nos invadió.  El esfuerzo valió la pena cuando recibimos los máximos honores y reconocimiento por nuestro ingenio y habilidades técnicas. Aquel hackatón no solo fue una prueba de nuestras habilidades, sino también una experiencia inolvidable de trabajo en equipo, perseverancia y superación de desafíos.\n",
    "    * Durante una sesión práctica en el laboratorio, me encontré luchando por resolver un problema de ingeniería que parecía ser simple. A pesar de siempre destacar académicamente, me sentí frustrado al ver cómo mis compañeros de clase completaban la tarea con facilidad. Decidí tragarme mi orgullo y pedir ayuda a uno de mis compañeros. Con humildad, me acerqué a él y le expliqué mi situación. Para mi sorpresa, él no solo me ofreció su ayuda, sino que también me guió pacientemente a través del problema. Juntos, trabajamos en equipo para encontrar la solución. A medida que avanzábamos, ganaba un nuevo aprecio por el valor de la humildad y el poder del trabajo en equipo en la búsqueda del conocimiento. Al final, no solo encontramos la solución al problema, sino que también fortalecimos nuestra amistad y aprendí una valiosa lección sobre la importancia de pedir ayuda cuando la necesito y reconocer que siempre hay algo nuevo que aprender de los demás.\n",
    "    * Una noche durante la semana de exámenes finales, decidimos, un grupo de estudiantes de ingeniería, tomar un respiro de tanto estudio y aventurarnos a explorar el campus. Mientras caminábamos, nos encontramos con el jardín en la azotea de la universidad, un lugar que rara vez visitábamos. La puerta que conducía a la sala de máquinas estaba desbloqueada, y con una mezcla de curiosidad y travesura, decidimos aventurarnos dentro. Una vez dentro, nos sumergimos en la oscuridad de la sala, apenas iluminada por la luz de nuestros teléfonos. Nos movíamos con cautela, explorando cada rincón con la emoción de estar en un lugar prohibido. Sin embargo, nuestro entusiasmo se convirtió rápidamente en preocupación cuando uno de nosotros tropezó con un interruptor y, en un instante, la sala quedó sumida en la oscuridad total. El pánico se apoderó de nosotros mientras intentábamos encontrar una solución. La idea de haber dejado a toda la universidad a oscuras nos llenó de nerviosismo y culpabilidad. Finalmente, después de unos momentos de caos, logramos restaurar la energía y devolver la luz a la universidad. Fue una experiencia que nunca olvidaremos. Aprendimos una valiosa lección sobre la importancia de la precaución y la humildad. A veces, la curiosidad puede llevarnos a situaciones inesperadas, pero es importante recordar que siempre debemos actuar con responsabilidad y consideración hacia los demás.\n",
    "    \"\"\".format(student.get_name(), student.get_surname(), student.get_age(), student.get_branch())\n",
    "\n",
    "    # Conversation/Request\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": context},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    logging.info(\"Ejecutando solicitud para ChatCompletion (Título y Relato)...\")\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        # gpt-3.5-turbo-0125 -> default\n",
    "        messages=conversation,\n",
    "        max_tokens=450,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    logging.info(\"Solicitud completada, el relato y su título han sido creados con éxito!\")\n",
    "\n",
    "    message = response['choices'][0]['message']\n",
    "    raw_tale = message['content']\n",
    "    raw_title_end = raw_tale.index(\"\\n\")\n",
    "    title = raw_tale[0:raw_title_end].replace(\"Título: \", \"\").replace(\"\\\"\", \"\")\n",
    "    tale = raw_tale[raw_title_end+1:]\n",
    "\n",
    "    return title, tale\n",
    "\n",
    "def create_image(student: Student):\n",
    "    prompt = student.get_prompt()\n",
    "\n",
    "    logging.info(\"Ejecutando solicitud para Image create (Imagen de perfil)...\")\n",
    "    response = openai.Image.create(\n",
    "        model=\"dall-e-2\",\n",
    "        prompt=prompt,\n",
    "        size=\"1024x1024\",\n",
    "        quality=\"standard\",\n",
    "        n=1,\n",
    "    )\n",
    "\n",
    "    logging.info(\"Solicitud completada, la imagen de perfil ha sido creada con éxito!\")\n",
    "    \n",
    "    image_url = response.data[0].url\n",
    "\n",
    "    return image_url\n",
    "\n",
    "def create_audio(tale: str, folder: str, use_gtts: bool):\n",
    "    if use_gtts:\n",
    "        logging.info(\"Ejecutando solicitud para generar audio con gTTS (Audio del relato)...\")\n",
    "\n",
    "        tts = gTTS(text=tale, lang='es', tld='com.mx')\n",
    "        timestamp = get_timestamp()\n",
    "        file_name = \"{}/relato-{}.mp3\".format(folder, timestamp)\n",
    "        tts.save(file_name)\n",
    "        \n",
    "        logging.info(\"Solicitud completada, el audio del relato ha sido creado con éxito utilizando gTTS!\")\n",
    "        \n",
    "        return file_name\n",
    "    \n",
    "    logging.info(\"Ejecutando solicitud para generar audio con OpenAI (Audio del relato)...\")\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"tts-1\",\n",
    "        \"input\": tale,\n",
    "        \"voice\": \"echo\"\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {openai.api_key}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "    file_name = \"\"\n",
    "\n",
    "    response = requests.post('https://api.openai.com/v1/audio/speech', json=payload, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        timestamp = get_timestamp()\n",
    "        file_name = \"{}/relato-{}.mp3\".format(folder, timestamp)\n",
    "        with open(file_name, 'wb') as handler:\n",
    "            handler.write(response.content)\n",
    "        logging.info(\"Solicitud completada, el audio del relato ha sido creado con éxito utilizando OpenAI!\")\n",
    "    else:\n",
    "        logging.error(\"Error al convertir el relato en audio. Código: {}\".format(response.status_code))\n",
    "\n",
    "    return file_name\n",
    "\n",
    "# Set Logging format with timestamp\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=logging.INFO)\n",
    "\n",
    "# Set API Key\n",
    "openai.api_key = \"THE_KEY\"\n",
    "\n",
    "# Set Audio model:\n",
    "# * True: gTTS (Google Text-to-Speech) - Free\n",
    "# * False: OpenAI (Text-to-Speech) - Paid\n",
    "use_gtts = True\n",
    "\n",
    "# Ensure `students` path exists\n",
    "if not os.path.exists(\"students\"):\n",
    "    os.makedirs(\"students\")\n",
    "\n",
    "# Set System Role\n",
    "context = \"Eres un asistente de generación de contenido para un blog de relatos de estudiantes de ingeniería, que incorpora semanalmente el relato de un estudiante incluyendo además los datos de perfil y una foto del mismo\"\n",
    "\n",
    "# Step 1: Create Student\n",
    "student = create_student(context)\n",
    "logging.info(\"Estudiante creado: {}\".format(student))\n",
    "\n",
    "# Step 2: Create Bio\n",
    "bio = create_bio(context, student)\n",
    "student.set_bio(bio)\n",
    "logging.info(\"Bio creada: {}\".format(bio))\n",
    "\n",
    "# Step 3: Create Tale\n",
    "tale_title, tale = create_tale(context, student)\n",
    "student.set_tale_title(tale_title)\n",
    "student.set_tale(tale)\n",
    "logging.info(\"Relato creado: {}\\n{}\".format(tale_title, tale))\n",
    "\n",
    "# Store Student's data\n",
    "name = student.get_name().lower().translate(normalize)\n",
    "surname = student.get_surname().lower().translate(normalize)\n",
    "directory = \"students/{}.{}\".format(name, surname)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "file_name = \"{}/{}\".format(directory, 'data.json')\n",
    "with open(file_name, 'w') as f:\n",
    "    json.dump(student.to_dict(), f)\n",
    "\n",
    "# Step 4: Create Image\n",
    "image_url = create_image(student)\n",
    "image_name = download_image(image_url, directory)\n",
    "logging.info(\"Imagen de perfil guardada bajo el nombre: {}\".format(image_name))\n",
    "\n",
    "# Step 5: Create Tale Audio\n",
    "audio_name = create_audio(tale, directory, use_gtts)\n",
    "if audio_name != \"\":\n",
    "    logging.info(\"Audio del relato guardado bajo el nombre: {}\".format(audio_name))\n",
    "else:\n",
    "    logging.info(\"No se ha podido generar el audio del relato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383cb1d1-c6c5-475d-95f8-18c5088bbb13",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "### Cambios respecto a la Pre-Entrega 2\n",
    "1. Se agregó una llamada a la API de OpenAI. Para obtener mejores resultados, modificamos los prompt para separar la obtención de la bio del estudiante.\n",
    "2. Se incorporaron datos del estudiante para obtener una imagen de perfil mas descriptiva (longitud y color de pelo, color de ojos y expresión).\n",
    "3. Se incorporó la rama de ingeniería que sigue el estudiante, para obtener un relato mas enfocado y específico.\n",
    "4. Se eliminaron comillas de los prompts para ahorrar caracteres (tokens).\n",
    "5. Se corrigió el cálculo de costos. Se estaban utilizando aquelos de DALL-E 3, pero como mencionamos anteriormente, esta versión no esta disponible utilizando el token y de hecho, en el código se estaba utilizando la versión 2.\n",
    "6. Se incorporó la librearía `logging` de `Python` para mejorar y estandarizar los logs de la aplicación.\n",
    "\n",
    "### Notas\n",
    "1. No se obtuvieron buenos resultados para las imágenes de perfil generadas, el modelo presenta muchos problemas particularmente con los ojos y dientes:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"students/dalle2/perfil-1.png\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"students/dalle2/perfil-2.png\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"students/dalle2/perfil-3.png\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"students/dalle2/perfil-4.png\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "2. Se intentó cambiar de modelo a DALL-E 3 pero no está disponible utilizando el token:\n",
    "\n",
    "```\n",
    "openai.error.RateLimitError: Rate limit exceeded for images per minute in organization org-5H3cxsYuFEQw29oSu1QQtrgN. Limit: 0/1min. Current: 1/1min. Please visit https://platform.openai.com/docs/guides/rate-limits to learn how to increase your rate limit.\n",
    "```\n",
    "\n",
    "3. En contraposición a los items anteriores, utilizando los mismos prompts en [Playground](https://playground.com), las imágenes obtenidas fueron mucho mejores, incluso haciendo una mejor interpretación del pedido de una \"Foto de perfil...\". Cabe destacar que Playground utiliza el modelo `Stable Diffusion XL` y que lamentablemente no cuenta con una API. Debajo, los resultados obtenidos utilizando Playground:\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src=\"students/playground/perfil-5.png\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"students/playground/perfil-6.png\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"students/playground/perfil-7.png\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"students/playground/perfil-8.png\" alt=\"Girl in a jacket\" width=\"500\" height=\"600\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "4. También se intetó usar la [API de ModelsLab](https://docs.modelslab.com/image-generation/realtime-stable-diffusion/overview), pero no se logró hacerla funcionar.\n",
    "5. Se jugó con la temperatura para intentar obtener resultados mas diversos en los prompts, pero utilizando valores entre `0` y `0.3`, no notamos mayores diferencias.\n",
    "\n",
    "## Próximos pasos\n",
    "\n",
    "1. Se sugiere la incorporación de un prompt negativo para evitar el duplicado de perfiles. No es recomendable incluir todos los perfiles previamente generados en este prompt negativo porque con el tiempo podría disparar los costos. Lo que se recomienda es ejecutar una verificación en código, post generación de los datos básicos. En caso de detectarse un duplicado, se puede incorporar una instrucción específica para evitar repetir ese perfil en particular. Por ejemplos, si la verificación en código detecta que ya existe un perfil llamado \"Marina Lopez\", se podría incluir en el primer prompt la frase: \"Por favor evita el Nombre `Marina` y el Apellido `Lopez`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
